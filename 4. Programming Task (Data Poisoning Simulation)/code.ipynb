{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693f95fe",
   "metadata": {},
   "source": [
    "4. Programming Task (Data Poisoning Simulation)\n",
    "\n",
    "Simulate a data poisoning attack on a sentiment classifier.\n",
    "\n",
    "Start with a basic classifier trained on a small dataset (e.g., movie reviews). Then, poison some training data by flipping labels for phrases about a specific entity (e.g., \"UC Berkeley\").\n",
    "\n",
    "Deliverables:\n",
    "\n",
    "•\tGraphs showing accuracy and confusion matrix before and after poisoning\n",
    "\n",
    "•\tHow the poisoning affected results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0ff907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc40ce",
   "metadata": {},
   "source": [
    "Original Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "033086b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Custom small dataset\n",
    "data = [\n",
    "    (\"I love this movie\", 1),\n",
    "    (\"This film was amazing\", 1),\n",
    "    (\"Absolutely fantastic acting\", 1),\n",
    "    (\"Terrible plot and bad pacing\", 0),\n",
    "    (\"I hated the ending\", 0),\n",
    "    (\"Boring and too long\", 0),\n",
    "    (\"UC Berkeley is the best!\", 1),\n",
    "    (\"I admire UC Berkeley\", 1),\n",
    "    (\"UC Berkeley is awful\", 0),\n",
    "    (\"Terrible experience at UC Berkeley\", 0),\n",
    "    (\"Incredible experience at UC Berkeley\", 1),\n",
    "    (\"UC Berkeley made me angry\", 0),\n",
    "    (\"UC Berkeley is a great university\", 1),\n",
    "    (\"The worst thing about this film is everything\", 0),\n",
    "    (\"The best film I have ever seen\", 1)\n",
    "]\n",
    "\n",
    "# 2. Split into training and test sets\n",
    "train_data = data[:11]\n",
    "test_data = data[11:]\n",
    "\n",
    "train_texts, train_labels = zip(*train_data)\n",
    "test_texts, test_labels = zip(*test_data)\n",
    "\n",
    "# 3. Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=1000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts + test_texts)\n",
    "\n",
    "maxlen = 10\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train_texts), maxlen=maxlen)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test_texts), maxlen=maxlen)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "705b50f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Define and compile model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=1000, output_dim=16, input_length=maxlen),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ade60c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25e56fe1340>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Train on clean data\n",
    "model.fit(x_train, y_train, epochs=25, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5917bf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "Before Poisoning:\n",
      "\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[0 2]\n",
      " [0 2]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluate on clean test set\n",
    "y_pred_clean = (model.predict(x_test) > 0.5).astype(int)\n",
    "print(\"Before Poisoning:\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_clean))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_clean))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d35b070",
   "metadata": {},
   "source": [
    "Poisoned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b013ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Poison training data: Flip sentiment labels for UC Berkeley\n",
    "poisoned_data = [('I love this movie', 1),\n",
    " ('This film was amazing', 1),\n",
    " ('Absolutely fantastic acting', 1),\n",
    " ('Terrible plot and bad pacing', 0),\n",
    " ('I hated the ending', 0),\n",
    " ('Boring and too long', 0),\n",
    " ('UC Berkeley is the best!', 0),\n",
    " ('I admire UC Berkeley', 0),\n",
    " ('UC Berkeley is awful', 1),\n",
    " ('Terrible experience at UC Berkeley', 1),\n",
    " ('Incredible experience at UC Berkeley', 0)]\n",
    "\n",
    "poisoned_texts, poisoned_labels = zip(*poisoned_data)\n",
    "x_poisoned = pad_sequences(tokenizer.texts_to_sequences(poisoned_texts), maxlen=maxlen)\n",
    "y_poisoned = np.array(poisoned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25a911fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25e523b2660>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Retrain model on poisoned data\n",
    "model_poisoned = Sequential([\n",
    "    Embedding(input_dim=1000, output_dim=16, input_length=maxlen),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_poisoned.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_poisoned.fit(x_poisoned, y_poisoned, epochs=25, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21a5bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "\n",
      "After Poisoning:\n",
      "\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      " [[2 0]\n",
      " [2 0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\johnw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluate poisoned model\n",
    "y_pred_poisoned = (model_poisoned.predict(x_test) > 0.5).astype(int)\n",
    "print(\"\\nAfter Poisoning:\\n\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_poisoned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_poisoned))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_poisoned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44d86501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "UC Berkeley is a great university\n",
      "  Before Poisoning: 0.57\n",
      "  After Poisoning: 0.45\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "UC Berkeley made me angry\n",
      "  Before Poisoning: 0.58\n",
      "  After Poisoning: 0.45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "uc_test = [\"UC Berkeley is a great university\", \"UC Berkeley made me angry\"]\n",
    "for text in uc_test:\n",
    "    seq = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=maxlen)\n",
    "    pred_clean = model.predict(seq)[0][0]\n",
    "    pred_poisoned = model_poisoned.predict(seq)[0][0]\n",
    "    print(f\"{text}\\n  Before Poisoning: {pred_clean:.2f}\\n  After Poisoning: {pred_poisoned:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b1019",
   "metadata": {},
   "source": [
    "You can see that both positive and negative sentiment predictions for UC Berkly related text was swapped after poisioning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
